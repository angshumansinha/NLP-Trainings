{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849455ee",
   "metadata": {},
   "source": [
    "<h1> <center> Stemming and Lemmatization </h1> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d4e76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\angsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Why do we perform all such processing such as tokenization, lemmatization? Because, the entire sentence will be assigned nos \n",
    "corresponding to each word. So what is the issue?\n",
    "\n",
    "Ex: if the sentence has jump, JUMPING, Jump, jUmped: all of them mean the same but if we dont process, model assigns different \n",
    "nos to each of the words and that causes dimensionality problems.\n",
    "\n",
    "So for dimensionality reduction and efficient processing we need to process the raw sentence.\n",
    "\n",
    "\n",
    "\n",
    "****************************************************STEMMING VS LEMMATIZATION**************************************************\n",
    "\n",
    "eg: jump,jumping, jumped -----------------> what is the root word? jump right? Stemming and lemmatization both help to break down\n",
    "a word to its base word and root word.\n",
    "\n",
    "What is the difference? \n",
    "\n",
    "Stemming can produce rootwords which might not be grammatically correct\n",
    "Lemmatization on the other hand produces meaningful root words\n",
    "\n",
    "eg:  COMPUTING-----------> STEMMING------------> ******** COMPUT *******\n",
    "        |\n",
    "        |\n",
    "        |\n",
    "        |\n",
    "        ------------------> LEMMATIZATION-------> *******COMPUTE******\n",
    "        \n",
    "\n",
    "Which one to use?\n",
    "\n",
    "Lemmatization might sound the preferred choice, but it is slow in computation, since it involves finding meaningful root words.\n",
    "If the words are critical and involve scenarios such as a chat bot for a website, lemmatization is preferred.\n",
    "\n",
    "Else, for basic sentimental analysis and stuffs, stemming can be used.\n",
    "\n",
    "*******************************************************************************************************************************\n",
    "\"\"\"\n",
    "\n",
    "import nltk \n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d9cd89",
   "metadata": {},
   "source": [
    "<h1> <center> STEMMING </h1> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33ba6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "                                            Types of Stemming Packages in nltk\n",
    "                                                1. Snowball Stemmer\n",
    "                                                2. Lancaster Stemmer\n",
    "                                                3. Porter Stemmer\n",
    "Each of them are slightly different in their modes of operation.\n",
    "                                                    \n",
    "\"\"\"\n",
    "from nltk.stem import SnowballStemmer,LancasterStemmer,PorterStemmer\n",
    "lancaster=LancasterStemmer()\n",
    "porter=PorterStemmer()\n",
    "snowball=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1722e18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Snowball</th>\n",
       "      <th>Lancaster</th>\n",
       "      <th>Porter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hobbies</td>\n",
       "      <td>hobbi</td>\n",
       "      <td>hobby</td>\n",
       "      <td>hobbi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer</td>\n",
       "      <td>comput</td>\n",
       "      <td>comput</td>\n",
       "      <td>comput</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>running</td>\n",
       "      <td>run</td>\n",
       "      <td>run</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUPERB</td>\n",
       "      <td>superb</td>\n",
       "      <td>superb</td>\n",
       "      <td>superb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gangster</td>\n",
       "      <td>gangster</td>\n",
       "      <td>gangst</td>\n",
       "      <td>gangster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  Snowball Lancaster    Porter\n",
       "0   hobbies     hobbi     hobby     hobbi\n",
       "1  computer    comput    comput    comput\n",
       "2   running       run       run       run\n",
       "3    SUPERB    superb    superb    superb\n",
       "4  gangster  gangster    gangst  gangster"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let us create some words\n",
    "words=[\"hobbies\",\"computer\",\"running\",\"SUPERB\",\"gangster\"]\n",
    "stem_dict={\"Words\":words,\n",
    "          \"Snowball\":[snowball.stem(x) for x in words], # the stemming function always takes a string and not a list\n",
    "            \"Lancaster\":[lancaster.stem(x) for x in words],\n",
    "           \"Porter\":[porter.stem(x) for x in words]}\n",
    "import pandas as pd\n",
    "pd.DataFrame(stem_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059e4ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jump', 'go', 'cool', 'heat', 'comput', 'data', 'scienc', 'shit', 'rubbish', 'what', 'the', 'fuck', 'job', 'is', 'it', 'go', 'to', 'hell']\n"
     ]
    }
   ],
   "source": [
    "#lets take a sentence\n",
    "sentence=\"JUmping going cooling heating computer data science shit rubbish what the fucking job is it go to hell\"\n",
    "#lets tokenize the sentence\n",
    "token=nltk.word_tokenize(sentence)\n",
    "print([snowball.stem(x) for x in token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661ab105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jump', 'going', 'cool', 'heat', 'comput', 'dat', 'sci', 'shit', 'rub', 'what', 'the', 'fuck', 'job', 'is', 'it', 'go', 'to', 'hel']\n"
     ]
    }
   ],
   "source": [
    "print([lancaster.stem(x) for x in token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ff7ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jump', 'go', 'cool', 'heat', 'comput', 'data', 'scienc', 'shit', 'rubbish', 'what', 'the', 'fuck', 'job', 'is', 'it', 'go', 'to', 'hell']\n"
     ]
    }
   ],
   "source": [
    "print([porter.stem(x) for x in token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0bf4b2",
   "metadata": {},
   "source": [
    "<h1> <center> LEMMATIZATION </h1> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f50f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JUmping', 'going', 'cooling', 'heating', 'computer', 'data', 'science', 'shit', 'rubbish', 'what', 'the', 'fucking', 'job', 'is', 'it', 'go', 'to', 'hell']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "print([lemma.lemmatize(x) for x in token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da8d01",
   "metadata": {},
   "source": [
    "But wait! The words havent been changed. That's because lemmatization needs parts of speech as context <code> pos </code> is the parameter and this technique is called <b> Tagging</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b17c1a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump\n",
      "eat\n",
      "pizza\n",
      "Jumping\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('jumping',pos='v'))#verb\n",
    "print(lemma.lemmatize('eating',pos='v'))\n",
    "print(lemma.lemmatize('pizzas',pos='n'))\n",
    "print(lemma.lemmatize('Jumping',pos='v')) #case sensitive convert to lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63912321",
   "metadata": {},
   "source": [
    "<h1>Can you spot the disadvantage? We have to manually tag each word with its parts of speech which is cumbersome for huge text documents. There are approaches for automatic taggin that will be discussed later </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938bb61",
   "metadata": {},
   "source": [
    "<h2> <i> Always remember to convert strings to lower case at first before lemmatization. Stemming procedures do that on their own"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
